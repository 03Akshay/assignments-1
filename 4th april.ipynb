{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11bebda8-2748-4e21-b033-338ff6c75611",
   "metadata": {},
   "source": [
    "## Q1. Describe the decision tree classifier algorithm and how it works to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6be5b2-cb61-4c94-a8d2-d7bf4be9b110",
   "metadata": {},
   "source": [
    "## \n",
    "The decision tree classifier is a popular algorithm used for both classification and regression tasks in machine learning. It is a non-linear and non-parametric algorithm that learns a hierarchy of decision rules from the training data to make predictions.\n",
    "\n",
    "Here's how the decision tree classifier works to make predictions:\n",
    "\n",
    "Building the Tree (Training):\n",
    "\n",
    "The algorithm starts with the entire dataset at the root node of the tree.\n",
    "It selects the best feature (attribute) from the dataset to split the data into subsets.\n",
    "The splitting criterion is typically based on metrics like Gini impurity or entropy for classification tasks, which aim to maximize information gain or minimize impurity in each subset.\n",
    "The dataset is divided into subsets based on the chosen feature's values, creating child nodes from the root node.\n",
    "\n",
    "The process is recursively repeated for each child node, selecting the best features to split the data in each subset until a stopping condition is met. The stopping condition could be reaching a maximum depth, a minimum number of samples in a node, or any other user-defined criterion.\n",
    "\n",
    "Making Predictions (Testing):\n",
    "\n",
    "To make predictions, a new data point is passed down the tree through the decision nodes based on the values of the features.\n",
    "\n",
    "At each decision node, the algorithm checks the value of the corresponding feature and follows the appropriate branch to the next node.\n",
    "\n",
    "This process is repeated until the data point reaches a leaf node, where the final prediction is made.\n",
    "For classification tasks, the prediction at a leaf node is typically the majority class of the samples in that node (i.e., the class with the most occurrences).\n",
    "For regression tasks, the prediction at a leaf node is usually the mean or median value of the target variable in that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8551d3-a2e1-407a-884f-1de8e0c1f2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a decision tree classifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc487b41-9ea5-4e9f-97a8-668718030215",
   "metadata": {},
   "source": [
    "## Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e98fd0f-2a7c-447c-a234-ed1ac9acc432",
   "metadata": {},
   "source": [
    "## \n",
    "Sure! Let's provide a step-by-step explanation of the mathematical intuition behind decision tree classification:\n",
    "\n",
    "Entropy and Information Gain:\n",
    "\n",
    "Entropy is a measure of uncertainty or impurity in a dataset. In the context of decision trees, it quantifies how much information is required to describe the target variable's distribution in a given node.\n",
    "\n",
    "Mathematically, for a binary classification problem, the entropy (H) at a node with respect to class labels \"0\" and \"1\" is calculated as:\n",
    "\n",
    "H(node) = - p(0) * log2(p(0)) - p(1) * log2(p(1))\n",
    "\n",
    "Where p(0) is the proportion of class \"0\" instances and p(1) is the proportion of class \"1\" instances in the node.\n",
    "\n",
    "Information Gain (IG) is used to measure the reduction in entropy after a dataset is split on a particular feature. It quantifies how much the decision tree's structure will reduce the dataset's uncertainty by considering the split.\n",
    "\n",
    "Splitting Criterion (Gini Impurity):\n",
    "\n",
    "Another common measure used for binary classification problems is Gini impurity, which measures the probability of misclassifying a randomly chosen element if it was randomly labeled according to the distribution of the class labels at that node.\n",
    "\n",
    "Gini impurity (G) for a node is calculated as:\n",
    "\n",
    "G(node) = 1 - Σ (p(i)^2)\n",
    "\n",
    "Where p(i) is the proportion of instances of class \"i\" in the node.\n",
    "\n",
    "Similar to information gain, the Gini impurity is used to evaluate the quality of a split for a given feature.\n",
    "\n",
    "Recursive Splitting:\n",
    "\n",
    "The decision tree algorithm uses a recursive approach to construct the tree. At each node, it iterates through all features and calculates the information gain or Gini impurity for each possible split.\n",
    "The feature with the highest information gain or the lowest Gini impurity is chosen as the splitting feature for that node.\n",
    "\n",
    "The data is then split into subsets based on the chosen feature, creating child nodes.\n",
    "The process is recursively repeated for each child node until a stopping criterion is met (e.g., reaching a maximum depth or a minimum number of samples in a node).\n",
    "\n",
    "Leaf Node Prediction:\n",
    "\n",
    "When creating the tree, if a stopping criterion is met, or if there are no more features left to split, the node becomes a leaf node.\n",
    "\n",
    "For classification tasks, the class label of the majority of instances in that node is used as the prediction for that leaf node.\n",
    "\n",
    "For regression tasks, the mean or median value of the target variable in that node is used as the prediction.\n",
    "By recursively splitting the dataset based on the features that provide the best information gain or Gini impurity reduction, the decision tree algorithm constructs a tree that can be used for classification tasks, providing an intuitive, interpretable, and non-linear decision boundary to separate different classes. This process allows the model to learn complex decision rules from the data and make predictions on new instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01815945-8f0d-47fe-ad24-d04935d84bbc",
   "metadata": {},
   "source": [
    "## Q3. Explain how a decision tree classifier can be used to solve a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d75501-fc39-44cf-a38e-479ce0e07ede",
   "metadata": {},
   "source": [
    "## \n",
    "A decision tree classifier can be used to solve a binary classification problem by learning a hierarchy of decision rules based on the input features to predict one of two possible classes: \"0\" or \"1.\" The decision tree algorithm recursively partitions the data into subsets based on the values of the input features until it reaches leaf nodes, where the final predictions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be0f965-ab17-49b6-9817-c59eef7d5738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82        89\n",
      "           1       0.87      0.84      0.85       111\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.84      0.84      0.84       200\n",
      "weighted avg       0.84      0.84      0.84       200\n",
      "\n",
      "Confusion Matrix:\n",
      "[[75 14]\n",
      " [18 93]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Generate a synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a decision tree classifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and other metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d3ddb1-0efa-463e-a717-7e80bff2a023",
   "metadata": {},
   "source": [
    "## Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196dc3c7-fae7-4146-a2f8-1361e1eec3bc",
   "metadata": {},
   "source": [
    "## \n",
    "The geometric intuition behind decision tree classification lies in the process of recursively partitioning the feature space into regions that correspond to different class labels. Each decision node in the tree represents a region in the feature space, and the tree's structure creates a set of nested rectangles (for 2D data) or hyper-rectangles (for higher-dimensional data) that define the decision boundaries between the classes.\n",
    "\n",
    "Here's how the geometric intuition of decision tree classification works:\n",
    "\n",
    "Decision Boundaries:\n",
    "\n",
    "At the root of the decision tree, the entire feature space is represented by a single region.\n",
    "The first decision node represents a splitting feature and its threshold value. This decision node divides the feature space into two regions based on whether the instances satisfy the condition (feature value <= threshold) or not.\n",
    "\n",
    "Each child node of the first decision node further divides its region based on a different splitting feature and threshold, creating smaller and more refined regions.\n",
    "\n",
    "Hierarchy of Rectangles:\n",
    "\n",
    "The recursive nature of the decision tree creates a hierarchy of rectangles (or hyper-rectangles) that represent different regions in the feature space.\n",
    "\n",
    "As you move down the tree, the regions become smaller and more specific, reflecting finer distinctions between classes based on the input features.\n",
    "\n",
    "Leaf Nodes and Predictions:\n",
    "\n",
    "\n",
    "At the leaf nodes of the decision tree, the regions have become small enough that each leaf node corresponds to a specific class label.\n",
    "\n",
    "For a binary classification problem, there will be two leaf nodes—one for each class.\n",
    "\n",
    "When making predictions on new instances, the decision tree follows the decision nodes' conditions to traverse down the tree and assign the instance to the appropriate leaf node region.\n",
    "\n",
    "The final prediction is the class label associated with the leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b2e47-ba77-48ef-b8a5-62583d1c461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Generate a synthetic binary classification dataset\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_classes=2, random_state=42)\n",
    "\n",
    "# Create a decision tree classifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the data\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Meshgrid to visualize decision boundaries\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict on the meshgrid to obtain decision boundaries\n",
    "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundaries and data points\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Decision Tree Classifier Decision Boundaries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6d15b-b258-4818-99dc-0becfce9ad94",
   "metadata": {},
   "source": [
    "## Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272af15-5f18-4e39-a9e7-5685d5b4a54a",
   "metadata": {},
   "source": [
    "##\n",
    "The confusion matrix is a table that is used to evaluate the performance of a classification model, particularly for binary classification tasks. It provides a detailed breakdown of the model's predictions and actual class labels, allowing us to analyze the model's performance in terms of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions.\n",
    "\n",
    "In a binary classification problem, the confusion matrix is structured as follows:\n",
    "\n",
    "True Positive (TP): The number of instances correctly predicted as positive (actual positive, predicted positive).\n",
    "\n",
    "True Negative (TN): The number of instances correctly predicted as negative (actual negative, predicted negative).\n",
    "\n",
    "False Positive (FP): The number of instances incorrectly predicted as positive (actual negative, predicted positive).\n",
    "\n",
    "False Negative (FN): The number of instances incorrectly predicted as negative (actual positive, predicted negative).\n",
    "\n",
    "Using the confusion matrix, various performance metrics can be derived to evaluate the classification model:\n",
    "\n",
    "Accuracy: The overall accuracy of the model, calculated as (TP + TN) / (TP + TN + FP + FN). It measures the percentage of correct predictions out of all predictions.\n",
    "\n",
    "Precision: Also known as positive predictive value, it is calculated as TP / (TP + FP). It represents the percentage of true positive predictions out of all positive predictions. It measures the model's ability to correctly identify positive instances.\n",
    "\n",
    "Recall (Sensitivity or True Positive Rate): Calculated as TP / (TP + FN). It represents the percentage of true positive predictions out of all actual positive instances. It measures the model's ability to capture all positive instances.\n",
    "\n",
    "Specificity (True Negative Rate): Calculated as TN / (TN + FP). It represents the percentage of true negative predictions out of all actual negative instances. It measures the model's ability to capture all negative instances.\n",
    "\n",
    "F1 Score: The harmonic mean of precision and recall, calculated as 2 * (precision * recall) / (precision + recall). It provides a balanced measure between precision and recall.\n",
    "\n",
    "ROC Curve and AUC: The Receiver Operating Characteristic (ROC) curve is a graphical representation of the model's true positive rate (recall) against the false positive rate (1 - specificity) as the classification threshold varies. The Area Under the Curve (AUC) summarizes the ROC curve's performance, with higher AUC values indicating better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe04d32-516d-4a63-8107-b6adbb136dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming y_true and y_pred are the actual and predicted class labels, respectively\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53683c65-519f-4337-b8e6-f49e70141818",
   "metadata": {},
   "source": [
    "## Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15de30c-e0d0-4c16-91d6-97b5ac4013ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2 2]\n",
      " [2 4]]\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "y_true = [1, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
    "y_pred = [1, 0, 0, 1, 1, 0, 1, 1, 0, 1]\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d3fc07-314e-477e-a8d1-769e1354ea28",
   "metadata": {},
   "source": [
    "## Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcffcac-659d-40f6-8e01-bcb50cad7ec1",
   "metadata": {},
   "source": [
    "##\n",
    "Choosing an appropriate evaluation metric for a classification problem is crucial because it directly impacts how you assess the performance of your model and make decisions about its effectiveness. Different evaluation metrics highlight different aspects of model performance, and the choice of metric should align with the specific goals and requirements of the problem at hand.\n",
    "\n",
    "Here's why choosing the right evaluation metric is important:\n",
    "\n",
    "Aligning with Business Objectives: The evaluation metric should be selected based on the business objectives of the project. For example, in a medical diagnosis application, correctly identifying true positive cases (high recall) might be more critical than overall accuracy.\n",
    "\n",
    "Handling Class Imbalance: If your dataset has imbalanced class distribution (i.e., one class is much more prevalent than the other), accuracy may not be an appropriate metric. Other metrics like precision, recall, or F1 score can provide a more balanced view of model performance.\n",
    "\n",
    "Addressing Costs and Risks: Different misclassification errors may have different costs or risks associated with them. For example, in a fraud detection system, a false negative (missed fraud) could be very costly. In such cases, recall becomes more important.\n",
    "\n",
    "Understanding Model Trade-offs: Different evaluation metrics reflect trade-offs between different aspects of model performance. Precision focuses on minimizing false positives, while recall focuses on minimizing false negatives. The F1 score balances both.\n",
    "\n",
    "Comparing Models: When comparing different models or tuning hyperparameters, using the same evaluation metric provides a fair basis for comparison.\n",
    "\n",
    "To choose an appropriate evaluation metric for a classification problem in Python:\n",
    "\n",
    "Understand the Problem: Clearly define the problem and the desired outcome. Consider the implications of different types of errors and how they impact the application.\n",
    "\n",
    "Analyze the Data: Investigate the class distribution, the presence of class imbalance, and the business context. This will help you identify the most relevant evaluation metric.\n",
    "\n",
    "Consult Stakeholders: Involve domain experts and stakeholders to understand their priorities and requirements. Their input can guide you in selecting the most suitable metric.\n",
    "\n",
    "Select Multiple Metrics: Sometimes, using multiple metrics is informative. For example, if you care about both precision and recall, evaluating both can give you a better understanding of the model's performance.\n",
    "\n",
    "Use Cross-Validation: When evaluating models on a limited dataset, use techniques like cross-validation to get a more robust estimate of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6415641-da37-4728-b292-72f8863792e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming y_true and y_pred are the actual and predicted class labels, respectively\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d24be-4f3d-4fa8-8d88-0f3972b97cb8",
   "metadata": {},
   "source": [
    "## Q8. Provide an example of a classification problem where precision is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5f4b9-5c34-416f-a416-cee643f437fd",
   "metadata": {},
   "source": [
    "##\n",
    "Let's consider a classification problem where precision is the most important metric. One such scenario could be a spam email classification system.\n",
    "\n",
    "In a spam email classification system, the goal is to identify whether an incoming email is a spam (positive class) or not (negative class). In this context, precision is a crucial metric because the consequences of a false positive (misclassifying a non-spam email as spam) can be severe.\n",
    "\n",
    "Here's why precision is the most important metric in a spam email classification system:\n",
    "\n",
    "Minimizing False Positives: False positives occur when the model incorrectly identifies a legitimate email as spam. This can lead to important emails being sent to the spam folder, causing users to miss critical information, communications, or opportunities.\n",
    "\n",
    "Avoiding Negative User Experience: Sending non-spam emails to the spam folder can result in a negative user experience. Users might become frustrated or lose trust in the email service if their legitimate emails are continuously misclassified as spam.\n",
    "\n",
    "Regulatory Compliance: For businesses, misclassifying important emails as spam could result in legal and regulatory implications. Certain industries, such as finance or healthcare, have strict requirements for handling sensitive information, and false positives could lead to compliance violations.\n",
    "\n",
    "To prioritize precision in this classification problem, you would want to ensure that the model's false positive rate is minimized. You are willing to accept a potentially higher false negative rate (missed spam emails) to avoid misclassifying legitimate emails as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18f35e14-0855-42cf-89b4-10a59c096c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, confusion_matrix\n",
    "\n",
    "# Sample data for demonstration\n",
    "emails = [\n",
    "    \"Buy our new product! Limited offer!\",\n",
    "    \"Dear customer, your invoice is attached.\",\n",
    "    \"Congratulations, you've won a prize!\",\n",
    "    \"Please find the report attached for review.\",\n",
    "    \"Claim your reward now!\",\n",
    "]\n",
    "\n",
    "labels = [1, 0, 1, 0, 1]  # 1 for spam, 0 for not spam\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the email content using TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Create and train a logistic regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064bf58-771b-43a3-bff2-bc4e505359ba",
   "metadata": {},
   "source": [
    "## Q9. Provide an example of a classification problem where recall is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0549a-cb95-41e6-9de8-485dc977e01e",
   "metadata": {},
   "source": [
    "##\n",
    "Let's consider a classification problem where recall is the most important metric. One such scenario could be a medical diagnosis application, specifically for identifying patients with a rare and potentially life-threatening disease.\n",
    "\n",
    "In this medical diagnosis application, the goal is to detect the presence of the rare disease (positive class) in patients based on various medical tests and symptoms. In such cases, recall is a crucial metric because the consequences of a false negative (misclassifying a patient with the disease as negative) can be severe and life-threatening.\n",
    "\n",
    "Here's why recall is the most important metric in this medical diagnosis application:\n",
    "\n",
    "Minimizing False Negatives: False negatives occur when the model incorrectly identifies a patient with the disease as negative (not having the disease). In a medical context, this can lead to a missed diagnosis, delayed treatment, and potential adverse outcomes for the patient.\n",
    "\n",
    "Early Detection and Treatment: For rare and severe diseases, early detection and treatment are critical for better patient outcomes. A high recall ensures that a significant proportion of patients with the disease are correctly identified, facilitating timely intervention.\n",
    "\n",
    "Patient Safety and Well-being: Misclassifying a patient with the disease as negative can result in the patient not receiving necessary medical attention, leading to worsening health conditions and compromised patient safety.\n",
    "\n",
    "To prioritize recall in this classification problem, you would want to ensure that the model's false negative rate is minimized. You are willing to accept a potentially higher false positive rate (misclassifying a healthy patient as positive) to avoid missing any patients with the rare disease.\n",
    "\n",
    "In Python, you can implement a medical diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9be37b57-55f8-4452-8ac8-f20764ef09e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "\n",
    "# Sample data for demonstration\n",
    "# Assume 1 represents patients with the disease, and 0 represents healthy patients.\n",
    "patient_data = [\n",
    "    [50, 160],  # Patient with the disease (positive class)\n",
    "    [55, 165],  # Patient with the disease (positive class)\n",
    "    [65, 180],  # Patient with the disease (positive class)\n",
    "    [70, 175],  # Healthy patient (negative class)\n",
    "    [60, 170],  # Healthy patient (negative class)\n",
    "]\n",
    "\n",
    "labels = [1, 1, 1, 0, 0]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(patient_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a logistic regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
