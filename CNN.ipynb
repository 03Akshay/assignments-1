{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33675208-79cd-4b27-85fa-77a29b6fe595",
   "metadata": {},
   "source": [
    "# #TOPIC: Understanding Pooling and Padding in CNN\n",
    "\n",
    "TOPIC: Exploring LeNet\n",
    "\n",
    "TOPIC: Analyzing AlexNet\n",
    "\n",
    "Submission Guidelines:\n",
    "bp Desccire the pucpose and renejits oj pooling in CNNp\n",
    "ip Explain the dijjecence retween Xin pooling and Xax poolingp\n",
    "Wp Discuss the concept oj padding in CNN and its signijicancep\n",
    "qp CoXpace and contcast zeco-padding and valid-padding in tecXs oj theic ejjects on the output\n",
    "jeatuce Xap size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f37024-d946-4fbc-b188-57dc537b9687",
   "metadata": {},
   "source": [
    "**Understanding Pooling in CNN:**\n",
    "\n",
    "Pooling is a critical operation in Convolutional Neural Networks (CNNs) used to downsample the spatial dimensions of feature maps generated by convolutional layers. The purpose of pooling is to reduce the spatial resolution of the feature maps while retaining important information. It offers several benefits:\n",
    "\n",
    "1. **Dimensionality Reduction:** Pooling reduces the size of the feature maps, leading to a more compact and manageable representation of the data. This reduces the computational complexity in subsequent layers.\n",
    "\n",
    "2. **Translation Invariance:** Pooling helps to make the model more robust to translations in the input data. It does this by considering local regions of the feature maps and summarizing them, making the model less sensitive to exact spatial positions.\n",
    "\n",
    "3. **Feature Generalization:** By summarizing local regions, pooling allows the model to focus on the most important features while ignoring minor variations.\n",
    "\n",
    "4. **Computation Efficiency:** Smaller feature maps require fewer parameters and computation, leading to faster training and inference times.\n",
    "\n",
    "**Difference between Max Pooling and Average Pooling:**\n",
    "\n",
    "Max Pooling and Average Pooling are two common types of pooling used in CNNs:\n",
    "\n",
    "1. **Max Pooling:** In this type of pooling, the maximum value within each pooling window is selected as the representative value for that region. Max pooling is more commonly used as it helps preserve sharp edges and features, making it suitable for tasks like object detection and localization.\n",
    "\n",
    "2. **Average Pooling:** In this type of pooling, the average of the values within each pooling window is taken as the representative value for that region. Average pooling can help in reducing the effect of noise and can be useful in certain situations.\n",
    "\n",
    "In general, Max Pooling is more popular because it introduces a form of spatial invariance, focusing on the most activated feature in a local region, which is often more useful for image recognition tasks.\n",
    "\n",
    "**Padding in CNN:**\n",
    "\n",
    "Padding is a technique used to preserve the spatial dimensions of feature maps when applying convolutions or pooling operations. When a convolutional or pooling layer is applied to an input, the spatial dimensions of the feature maps decrease. Padding involves adding extra pixels around the border of the input to maintain the spatial size after the operation. Padding is typically done with zeros (zero-padding), but it can also be done with other values.\n",
    "\n",
    "**Significance of Padding:**\n",
    "\n",
    "1. **Avoiding Border Information Loss:** Without padding, the borders of the input data receive fewer convolutions and pooling operations, leading to loss of information. Padding helps retain information near the borders.\n",
    "\n",
    "2. **Preserving Output Size:** Padding ensures that the output of convolution and pooling operations matches the input size, making it easier to design deep networks.\n",
    "\n",
    "**Zero-padding vs. Valid-padding:**\n",
    "\n",
    "1. **Zero-padding:** In zero-padding, zeros are added to the border of the input data. If we add p pixels of zero padding to all sides of the input, the spatial dimensions of the output feature maps will be preserved. If you apply a convolution or pooling operation to the padded input, the output will have the same size as the original input.\n",
    "\n",
    "2. **Valid-padding:** In valid-padding, no padding is added to the input data. As a result, the spatial dimensions of the output feature maps decrease. Valid-padding leads to a reduction in the spatial dimensions of the output compared to the input.\n",
    "\n",
    "**Justification of Output Feature Map Size (Xap size):**\n",
    "\n",
    "Given an input size (I), kernel/filter size (K), stride (S), and padding (P), the output size (O) of a convolution or pooling operation can be calculated using the formula:\n",
    "\n",
    "O = (I - K + 2P)/S + 1\n",
    "\n",
    "Where:\n",
    "- I: Input size\n",
    "- K: Kernel/Filter size\n",
    "- S: Stride\n",
    "- P: Padding\n",
    "- O: Output size (feature map size)\n",
    "\n",
    "By choosing appropriate values for K, S, and P, you can control the size of the feature maps and the spatial resolution of the network's outputs. This formula helps to ensure that the output size is suitable for subsequent layers in the CNN architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05866b-5458-4413-8b76-094cb81f1a2f",
   "metadata": {},
   "source": [
    "# #OPIC: Exploring LeNet\n",
    "bp Pcovide a rciej ovecview oj LeNet-5 acchitectucep\n",
    "ip Desccire the ke¢ coXponents oj LeNet-5 and theic cespective pucposesp\n",
    "Wp Discuss the advantages and liXitations oj LeNet-5 in the context oj iXage classijication tasksp\n",
    "qp IXpleXent LeNet-5 using a deep leacning jcaXewock oj ¢ouc choice (e.g., TensocFlow, P¢Tocch) and tcain it on a purlicl¢ availarle dataset (e.g., MNIST). Evaluate its pecjocXance and pcovide\n",
    "insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf78f5-aba8-43b0-ab26-f7d0d37c8238",
   "metadata": {},
   "source": [
    "**Overview of LeNet-5 Architecture:**\n",
    "LeNet-5 is one of the pioneering convolutional neural network (CNN) architectures developed by Yann LeCun in 1998. It was primarily designed for handwritten digit recognition, such as the MNIST dataset. LeNet-5 played a significant role in popularizing CNNs and laid the foundation for modern deep learning approaches for computer vision tasks.\n",
    "\n",
    "**Key Components of LeNet-5 and their Purposes:**\n",
    "\n",
    "1. **Input Layer:** The input to LeNet-5 is a grayscale image of size 32x32 pixels. This is a significant departure from the traditional high-resolution images, which makes LeNet-5 computationally efficient and suitable for handwritten digit recognition.\n",
    "\n",
    "2. **Convolutional Layers:** LeNet-5 comprises two sets of convolutional layers. The first convolutional layer has six filters (also called kernels) of size 5x5. The second convolutional layer has 16 filters of size 5x5. These filters are applied to the input images to extract different patterns and features.\n",
    "\n",
    "3. **Activation Function (ReLU):** Rectified Linear Unit (ReLU) activation is applied after each convolutional and fully connected layer. ReLU introduces non-linearity to the network and helps in better feature representation and training convergence.\n",
    "\n",
    "4. **Pooling Layers:** LeNet-5 uses average pooling after the first convolutional layer and max pooling after the second convolutional layer. Pooling layers downsample the spatial dimensions, reducing computation and aiding in translation invariance.\n",
    "\n",
    "5. **Fully Connected Layers:** The output of the second pooling layer is flattened and fed into three fully connected layers. The first fully connected layer has 120 units, followed by a layer with 84 units. The final fully connected layer has 10 units, representing the 10 possible digits (0 to 9) for classification.\n",
    "\n",
    "6. **Softmax Activation:** The output layer uses the softmax activation function to convert the raw scores into probabilities. It assigns a probability to each digit class, indicating the likelihood of the input image belonging to that class.\n",
    "\n",
    "**Advantages and Limitations of LeNet-5:**\n",
    "\n",
    "**Advantages:**\n",
    "- Simple Architecture: LeNet-5 has a straightforward and elegant design, making it easy to understand and implement.\n",
    "- Lightweight: Due to its relatively small size, it can be efficiently trained and used on small datasets like MNIST.\n",
    "- Introduces Convolution and Pooling: LeNet-5 introduced the concept of using convolutional layers and pooling, which are fundamental components of modern CNNs.\n",
    "\n",
    "**Limitations:**\n",
    "- Limited Depth: LeNet-5 has a shallow architecture, which restricts its performance on complex datasets with a large number of classes and diverse images.\n",
    "- Handcrafted Features: The features learned by LeNet-5 are limited by the manually designed filters. Modern CNNs overcome this limitation by learning more complex and abstract features through deeper architectures.\n",
    "- Image Resolution: LeNet-5 is designed to handle low-resolution images like those in the MNIST dataset. It may not perform well on high-resolution and more complex image datasets.\n",
    "\n",
    "**Implementing LeNet-5 on MNIST Dataset:**\n",
    "\n",
    "Below is a sample implementation of LeNet-5 using the PyTorch deep learning framework on the MNIST dataset:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define LeNet-5 architecture\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = MNIST(root='data/', train=True, transform=transform, download=True)\n",
    "test_dataset = MNIST(root='data/', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"LeNet-5 Accuracy on MNIST Test Set: {accuracy:.2f}%\")\n",
    "```\n",
    "\n",
    "The above code implements LeNet-5 on the MNIST dataset using PyTorch. It trains the model for 10 epochs and evaluates its performance on the test set. The accuracy achieved should be in the range of 98% to 99%, showcasing the efficiency of LeNet-5 on the simple MNIST digit classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4d1a80-747a-4919-8bd2-d2c56c6f0d69",
   "metadata": {},
   "source": [
    "# #TOPIC: Analyzing AlexNet\n",
    "bp Pcesent an ovecview oj the AlexNet acchitectucep\n",
    "ip Explain the acchitectucal innovations intcoduced in AlexNet that contciruted to its rceakthcough\n",
    "pecjocXancep\n",
    "Wp Discuss the cole oj convolutional la¢ecs, pooling la¢ecs, and jull¢ connected la¢ecs in AlexNetp\n",
    "qp IXpleXent AlexNet using a deep leacning jcaXewock oj ¢ouc choice and evaluate its pecjocXance\n",
    "on a dataset oj ¢ouc choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e952124-a597-46d8-b8b0-895dc3e7e046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
